{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\users\\atero\\Github\\projet-statistique-2022\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from gensim import models\n",
    "import numpy as np\n",
    "from typing import Callable\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import itertools\n",
    "from comparaison_BATS import *\n",
    "%cd \"..\"\n",
    "from clustering import k_medoides as k_med\n",
    "import distance_wmd as wmd\n",
    "import moyenne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/docs.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20268/4194071670.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/docs.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"utf8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mdocs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Nombre de documents : {len(docs)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/docs.json'"
     ]
    }
   ],
   "source": [
    "with open('../data/docs.json', encoding = \"utf8\") as f:\n",
    "    docs: list[str] = json.load(f)\n",
    "print(f\"Nombre de documents : {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du vocabulaire : 7231\n"
     ]
    }
   ],
   "source": [
    "with open('../data/liste_lemmes.txt') as f:\n",
    "    vocabulaire = f.readlines()\n",
    "\n",
    "# Suppression des retours chariots sur chaque ligne\n",
    "for i in range(len(vocabulaire)):\n",
    "    vocabulaire[i] = vocabulaire[i].replace('\\n', '')\n",
    "\n",
    "print(f\"Taille du vocabulaire : {len(vocabulaire)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création et entraînement basique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `vector_size` : taille de l'espace vectoriel de représentation des mots\n",
    "- `windows` : fenêtre gauche / droite de contexte\n",
    "- `min_count` : valeur fréquence absolue minimale que doit avoir un mot pour être inclus\n",
    "- `workers` : nombre de threads utilisés pour l'entraînement\n",
    "- `sg` : 1 si Skip-Gram, 0 si CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vec: models.Word2Vec = models.Word2Vec(sentences = docs, vector_size = 300, window = 2, min_count = 1, workers = 6, sg = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# espace vectoriel généré des mots\n",
    "ev = w2vec.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enregistrement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vec.save(\"../data/w2vec.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vec: models.Word2Vec = models.Word2Vec.load(\"../data/w2vec.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# espace vectoriel généré des mots\n",
    "ev = w2vec.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation qualitative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proximité de divers termes entre eux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mots_plus_proches(espace: models.KeyedVectors, mot: str, nbMots: int = 10, distance: str | Callable = 'cosine') -> list[str]:\n",
    "    resultats = {}\n",
    "    for v in vocabulaire:\n",
    "        if v != mot:\n",
    "            if distance == 'cosine':\n",
    "                resultats[v] = np.dot(espace[v], espace[mot]) / (np.linalg.norm(espace[v]) * np.linalg.norm(espace[mot]))\n",
    "\n",
    "    resultats = sorted(resultats.items(), key = lambda x: x[1], reverse = True)\n",
    "    for i in range(nbMots):\n",
    "        print(resultats[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('faire', 0.9997729)\n",
      "('nature', 0.9997668)\n",
      "('citoyen', 0.99976385)\n",
      "('être', 0.9997621)\n",
      "('france', 0.9997531)\n",
      "('environnement', 0.9997397)\n",
      "('biodiversite', 0.9997345)\n",
      "('pouvoir', 0.9997297)\n",
      "('pays', 0.99972695)\n",
      "('inciter', 0.9997259)\n"
     ]
    }
   ],
   "source": [
    "mots_plus_proches(ev, 'dechet', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mot_plus_proche(espace: models.KeyedVectors, vecteurMot: np.ndarray, nbMots: int = 5, distance: str | Callable = 'cosine') -> list[str]:\n",
    "    resultats = {}\n",
    "    for v in vocabulaire:\n",
    "        if distance == 'cosine':\n",
    "            resultats[v] = np.dot(espace[v], vecteurMot) / (np.linalg.norm(espace[v]) * np.linalg.norm(vecteurMot))\n",
    "\n",
    "    resultats = sorted(resultats.items(), key = lambda x: x[1], reverse = True)\n",
    "    for i in range(nbMots):\n",
    "        print(resultats[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dechet', 0.96101624)\n",
      "('selectif', 0.9606815)\n",
      "('chauffer', 0.96038085)\n",
      "('centre', 0.9601055)\n",
      "('eduquer', 0.9599925)\n"
     ]
    }
   ],
   "source": [
    "variation = ev['pluie'] - ev['eau']\n",
    "mot_plus_proche(ev, ev['dechet'] + variation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation quantitative (comparaison avec un modèle stable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "traducteur = GoogleTranslator(source='en',target='fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "récupération d'un modèle word2vec de référence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://fauconnier.github.io/#data\n",
    "\n",
    "frWiki2Vec\n",
    "\n",
    "bin (151Mb)\t∨\t-\t-\tskip\t1000\t100\t5ac9\n",
    "\n",
    "https://s3.us-east-2.amazonaws.com/embeddings.net/embeddings/frWiki_no_phrase_no_postag_1000_skip_cut100.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vecR: models.KeyedVectors = models.KeyedVectors.load_word2vec_format(\"../data/frWiki_no_phrase_no_postag_1000_skip_cut100.bin\", binary=True, unicode_errors=\"ignore\")\n",
    "vocabulaireCommun = set(vocabulaire).intersection(w2vecR.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_position_proximite(modele: models.KeyedVectors, motCentral: str, mot2: str, listeMots: list[str] = None, distance: str = 'cosine') -> int:\n",
    "\n",
    "    if listeMots is None:\n",
    "        listeMots = modele.index_to_key\n",
    "\n",
    "    listeMots = listeMots.copy()\n",
    "    listeMots.remove(motCentral)\n",
    "    distMots: list[float] = []\n",
    "    pos = 1\n",
    "\n",
    "    if distance == 'cosine':\n",
    "        distMots = modele.distances(motCentral, listeMots)\n",
    "        temp = sorted(distMots)\n",
    "        pos = [temp.index(distMots[i]) for i in range(len(distMots)) if listeMots[i] == mot2][0] + 1\n",
    "        #pos = modele.rank(motCentral, mot2)\n",
    "    \n",
    "    return pos, pos / len(listeMots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3304, 0.857736240913811)\n",
      "(2284, 0.592938733125649)\n"
     ]
    }
   ],
   "source": [
    "print(get_position_proximite(w2vecR, \"vie\", \"chocolat\", list(vocabulaireCommun)))\n",
    "print(get_position_proximite(w2vec.wv,  \"vie\", \"chocolat\", list(vocabulaireCommun)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation des proximités sous BATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/BATS_3.0/2_fr.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_20268/3237232518.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_stats_comparaisons_BATS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mev\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2vecR\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\users\\atero\\Github\\projet-statistique-2022\\word_embedding\\comparaison_BATS.py\u001b[0m in \u001b[0;36mget_stats_comparaisons_BATS\u001b[1;34m(modele, reference)\u001b[0m\n\u001b[0;32m    110\u001b[0m     \u001b[0mvocabulaire\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodele\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_to_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex_to_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m     \u001b[0mBATS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_BATS\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBATS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m     \u001b[0mstats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\users\\atero\\Github\\projet-statistique-2022\\word_embedding\\comparaison_BATS.py\u001b[0m in \u001b[0;36mget_BATS\u001b[1;34m()\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0mBATS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpathBATS\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_fr.txt\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m             \u001b[0mfichier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[0mBATS\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfichier\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/BATS_3.0/2_fr.txt'"
     ]
    }
   ],
   "source": [
    "get_stats_comparaisons_BATS(ev, w2vecR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moyenne des similarités entre chaque mot du vocabulaire des deux modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_comparaisons_intra_vocab(modele: models.KeyedVectors, reference: models.KeyedVectors):\n",
    "\n",
    "    vocabulaire = list(set(modele.index_to_key).intersection(reference.index_to_key))\n",
    "    stats = {}\n",
    "    stats['taille_vocab'] = len(vocabulaire)\n",
    "    stats['err_dis_cos'] = 0\n",
    "    n = 0\n",
    "    for mot1, mot2 in itertools.product(vocabulaire, vocabulaire):\n",
    "        n += 1\n",
    "        if mot1 == mot2:\n",
    "            continue\n",
    "        \n",
    "        # Distance cosinus\n",
    "        disMod = modele.distance(mot1, mot2)\n",
    "        disRef = modele.distance(mot1, mot2)\n",
    "        stats['err_dis_cos'] += disMod - disRef\n",
    "    \n",
    "    stats['err_dis_cos'] /= n\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_comparaisons_intra_vocab(ev, w2vecR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparamètres considérés : \n",
    "- Type de modèle (CBOW, Skip-Gram) ;\n",
    "- Taille de l'espace vectoriel (100 à 300) ;\n",
    "- Taille de la fenêtre de contexte (2 à 6) ;\n",
    "- Fréquence minimale des mots que l'on doit considérer (1, 2) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning(documents : list[str], modeleReference: models.KeyedVectors):\n",
    "\n",
    "    # Grille des hyperparamètres\n",
    "    typesModele = [0, 1]\n",
    "    taillesEV = range(100, 301, 50)\n",
    "    taillesFenetre = range(2, 7)\n",
    "    frequencesMin = [1, 2]\n",
    "\n",
    "    nbModeles: int = len(typesModele * len(taillesEV) * len(taillesFenetre) * len(frequencesMin))\n",
    "    print(f\"Nombre de modèles à tester : {nbModeles}\")\n",
    "    print(\"0 % | \", end = '')\n",
    "    tableauModeles = pd.DataFrame(columns = [\"type_modele\", \"dimension_ev\", \"taille_fenetre\", \"frequence_min\",\n",
    "    \"err_dis_cos\", 'rmse_dis_cos', 'err_moy_freq', 'rmse_freq'])\n",
    "\n",
    "    modelesFaits = 0\n",
    "    score = np.inf\n",
    "    bestModele: models.Word2Vec = None\n",
    "    meilleursHP = {}\n",
    "    # Réalisation d'un modèle pour chaque point de la grille\n",
    "    for typeModele, N, fenetre, frequenceMin in itertools.product(typesModele, taillesEV, taillesFenetre, frequencesMin):\n",
    "\n",
    "        modele = models.Word2Vec(sentences = documents,  vector_size = N, window = fenetre, min_count = frequenceMin, workers = 6, sg = typeModele)\n",
    "        stats = get_stats_comparaisons_BATS(modele.wv, modeleReference)\n",
    "\n",
    "        tableauModeles.loc[len(tableauModeles.index)] = [\"Skip-Gram\" if typeModele else \"CBOW\", N,\n",
    "        fenetre, frequenceMin, stats[\"err_dis_cos\"], stats[\"rmse_dis_cos\"], stats['err_moy_freq'], stats['rmse_freq']]\n",
    "        \n",
    "        modelesFaits += 1\n",
    "        if (percent := round(modelesFaits * 100 / nbModeles)) % 5 == 0 and round((modelesFaits -1) * 100 / nbModeles) != 0:\n",
    "            print(f\"{percent} % |\", end = \" \")\n",
    "\n",
    "    return tableauModeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    tableauModeles = tuning(docs, w2vecR)\n",
    "    tableauModeles\n",
    "    minRMSEDisCos = np.min(tableauModeles['rmse_dis_cos'])\n",
    "    tableauModeles.loc[tableauModeles['rmse_dis_cos'] == minRMSEDisCos, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Espace de documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Valeur moyenne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction suivante transforme un document en vecteurs en faisant la moyenne de la représentation vectorielle de ses mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = moyenne.word_emb_vers_doc_emb_moyenne(docs, ev, methode = 'TF-IDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01069216,  0.09773491, -0.01242723,  0.05093091, -0.00637252,\n",
       "       -0.09885354,  0.06334325,  0.1809077 ,  0.03335816, -0.01096502,\n",
       "       -0.00260904, -0.11205901,  0.0199743 , -0.03060548, -0.08978499,\n",
       "       -0.06843026,  0.02663438,  0.01296016,  0.04067067, -0.00452412,\n",
       "       -0.08665582,  0.00219414,  0.05796174,  0.00467753,  0.08714599,\n",
       "        0.01022187, -0.10834898, -0.01234061, -0.05879311, -0.07112122,\n",
       "        0.03182544, -0.0759148 ,  0.02959498, -0.01753111, -0.01756881,\n",
       "        0.01602495,  0.03089778, -0.09331328, -0.01461071,  0.00594171,\n",
       "       -0.05014352, -0.00627113,  0.01295382, -0.06517245,  0.03452049,\n",
       "        0.08875772,  0.03935783,  0.0270425 , -0.03710178,  0.0793754 ,\n",
       "        0.02437214, -0.00469619, -0.04391738,  0.0236082 , -0.01220939,\n",
       "        0.10608229,  0.04244157,  0.00305934,  0.01806995, -0.00810317,\n",
       "       -0.04574402, -0.02721521, -0.0208501 ,  0.02347451,  0.03609216,\n",
       "        0.02949356,  0.01807938, -0.00943914, -0.03105053, -0.04471164,\n",
       "       -0.00408888,  0.07004818,  0.09690171, -0.08280019, -0.00354028,\n",
       "        0.04104397, -0.08142812, -0.00422152, -0.00031353,  0.07130559,\n",
       "       -0.03098012, -0.08742565,  0.02398599,  0.14133996,  0.02605487,\n",
       "        0.0002433 , -0.06964283,  0.00567846,  0.05418878,  0.0328407 ,\n",
       "        0.08958876, -0.0417612 ,  0.0519792 ,  0.04458814,  0.06781299,\n",
       "        0.06863878,  0.08833504, -0.02708549, -0.05825524,  0.07176965,\n",
       "       -0.00346438, -0.03857201,  0.08515602, -0.00846756,  0.03333339,\n",
       "       -0.05884384, -0.02253071,  0.01793834, -0.04591523,  0.05885609,\n",
       "       -0.07207087, -0.03978828, -0.00541995,  0.05952806,  0.05488716,\n",
       "        0.04634562, -0.01497809, -0.02293665,  0.12356351, -0.07412975,\n",
       "        0.05770673,  0.0739914 ,  0.04262473, -0.00657844, -0.02623283,\n",
       "        0.03250235,  0.05817831, -0.08664013, -0.01269174,  0.02871514,\n",
       "        0.01738771,  0.08738835,  0.00865603, -0.06753657,  0.04860266,\n",
       "        0.0374684 , -0.02936651, -0.07017975, -0.06160158, -0.09406634,\n",
       "        0.02629061, -0.10244709,  0.0042633 ,  0.04476544,  0.05404776,\n",
       "       -0.03347964, -0.13280885, -0.02120832,  0.03435093, -0.03173396,\n",
       "        0.01880711, -0.13423058, -0.06754135, -0.0396691 ,  0.00336366,\n",
       "        0.03455614, -0.07303226, -0.03949124, -0.01539088,  0.08921894,\n",
       "        0.02437893,  0.0503684 , -0.12633577,  0.09804071, -0.05435291,\n",
       "        0.03623542,  0.01289306, -0.00290445,  0.04209072,  0.14614336,\n",
       "       -0.02147198, -0.00948218,  0.03679016,  0.02272354, -0.03491832,\n",
       "        0.01212817, -0.01282372, -0.07551452, -0.04095088, -0.0115369 ,\n",
       "       -0.04033655,  0.05595879, -0.04086009, -0.05136452, -0.00524596,\n",
       "        0.04666821,  0.07432207,  0.1032695 ,  0.03680776, -0.08007579,\n",
       "       -0.00907469, -0.01913828, -0.09791446,  0.00413276,  0.04070176,\n",
       "       -0.06220791,  0.01078442, -0.08838151,  0.04304972, -0.01281221,\n",
       "       -0.08786739,  0.02341216, -0.01242391, -0.03901654, -0.0304671 ,\n",
       "       -0.00717563, -0.0391168 ,  0.02695532,  0.0080789 , -0.0168849 ,\n",
       "        0.02040531, -0.05228474, -0.07332321, -0.02555405,  0.05036359,\n",
       "       -0.09075616,  0.00092412, -0.14456536, -0.11317829, -0.07070231,\n",
       "        0.09101747, -0.00084805, -0.06192052, -0.04579886, -0.04142232,\n",
       "       -0.06051123,  0.01414964, -0.0002163 , -0.06325808,  0.03772005,\n",
       "        0.07423314, -0.00115493, -0.05853871,  0.06057509, -0.02320373,\n",
       "        0.01075078, -0.00025999,  0.00931367,  0.02918754, -0.11537181,\n",
       "        0.0111392 , -0.0426897 , -0.06711008,  0.00765128, -0.01202242,\n",
       "       -0.09224136,  0.02510697,  0.02428689,  0.00641126,  0.0786062 ,\n",
       "       -0.00467739,  0.05292809,  0.02260302, -0.00178955, -0.11597981,\n",
       "       -0.06786226,  0.11678934,  0.0281713 , -0.12615927, -0.04087923,\n",
       "        0.05827506,  0.07919195, -0.01682748, -0.11143561, -0.05965469,\n",
       "       -0.0078904 ,  0.03820479,  0.04302009, -0.06523934,  0.01813422,\n",
       "       -0.05535501,  0.00882859, -0.0104217 , -0.03285914,  0.11162699,\n",
       "        0.00350471,  0.09403644,  0.01298789, -0.06201352, -0.00079703,\n",
       "        0.0701057 , -0.01515347, -0.01234659,  0.05455999,  0.02699322,\n",
       "       -0.02992478, -0.10495566,  0.03693136,  0.01987129,  0.10121167,\n",
       "       -0.0174037 ,  0.1026879 ,  0.10116756,  0.00341237,  0.08714376,\n",
       "        0.1204912 ,  0.01437283, -0.06404804,  0.04896909, -0.013562  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('supprimer', 0.9998861)\n",
      "('remplacer', 0.99963814)\n",
      "('papier', 0.9996263)\n",
      "('utilisation', 0.9995823)\n",
      "('utiliser', 0.99957883)\n"
     ]
    }
   ],
   "source": [
    "mot_plus_proche(ev, res[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['supprimer', 'suremballage']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Distance WMD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de distances à calculer : 4950.0\n",
      "0 % | 5 % | 10 % | 15 % | 20 % | 25 % | 30 % | 35 % | 40 % | 45 % | 50 % | 55 % | 60 % | 65 % | 70 % | 75 % | 80 % | 85 % | 90 % | 95 % | 100 % | Données enregistrées dans ../data/distances/distances.7z\n"
     ]
    }
   ],
   "source": [
    "wmd.distance_wmd_tous_docs(docs[:100], modele = ev, retour = 'fichier', toInteger = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     uint32\n",
       "1     uint32\n",
       "2     uint32\n",
       "3     uint32\n",
       "4     uint32\n",
       "       ...  \n",
       "95    uint32\n",
       "96    uint32\n",
       "97    uint32\n",
       "98    uint32\n",
       "99    uint32\n",
       "Length: 100, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wmd.lecture_fichier_distances_wmd().dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prend dans notre cas 3h45min environ de calcul\n",
    "if False:\n",
    "    wmddistance_wmd_tous_docs(docs, ev, retour = 'fichier', nomFichier = 'wmd/w2vec.txt', toInteger = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = wmd.lecture_fichier_distances_wmd('../data/wmd/w2vec.txt', integer = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycle 1 :\n",
      "Itération 1 : Création des groupes - Correction des tailles de groupe - part dans chaque groupe (%) : 5 5 80 5 5 (784 s) | Recherche du point moyen pour chaque groupe ( 0 1 2 3 4 ) - Stabilité des centres : X X X X X (194 s)\n",
      "Itération 2 : Création des groupes - Correction des tailles de groupe - part dans chaque groupe (%) : 6 10 39 5 39 (75 s) | Recherche du point moyen pour chaque groupe ( 0 1 2 3 4 ) - Stabilité des centres : V V X V V (97 s)\n",
      "Itération 3 : Création des groupes - Correction des tailles de groupe - part dans chaque groupe (%) : 6 9 61 5 19 (74 s) | Recherche du point moyen pour chaque groupe ( 0 1 2 3 4 ) - Stabilité des centres : V V V V V (128 s)\n",
      "Cycle 2 :\n",
      "Itération 1 : Création des groupes - Correction des tailles de groupe - part dans chaque groupe (%) : 80 5 5 5 5 (924 s) | Recherche du point moyen pour chaque groupe ( 0 1 2 3 4 ) - Stabilité des centres : X X X X X (205 s)\n",
      "Itération 2 : Création des groupes - Correction des tailles de groupe - part dans chaque groupe (%) : 5 41 24 23 7 (102 s) | Recherche du point moyen pour chaque groupe ( 0 1 2 3 4 ) - Stabilité des centres : X X X X X (93 s)\n",
      "Itération 3 : Création des groupes - Correction des tailles de groupe - part dans chaque groupe (%) : 59 5 11 16 8 (124 s) | Recherche du point moyen pour chaque groupe ( 0 1 2 3 4 ) - Stabilité des centres : X X X V X (129 s)\n",
      "Itération 4 : Création des groupes - part dans chaque groupe (%) : 10 58 10 14 7 (3 s) | Recherche du point moyen pour chaque groupe ( 0 1 2 3 4 ) - Stabilité des centres : V V X V V (122 s)\n",
      "Itération 5 : Création des groupes - part dans chaque groupe (%) : 10 59 8 15 8 (3 s) | Recherche du point moyen pour chaque groupe ( 0 1 2 3 4 ) - Stabilité des centres : V V X V V (125 s)\n",
      "Itération 6 : Création des groupes - part dans chaque groupe (%) : 10 59 7 15 9 (3 s) | Recherche du point moyen pour chaque groupe ( 0 1 2 3 4 ) - Stabilité des centres : V V V V V (127 s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       4\n",
       "4       4\n",
       "       ..\n",
       "9496    2\n",
       "9497    2\n",
       "9498    1\n",
       "9499    2\n",
       "9500    2\n",
       "Name: 2, Length: 9501, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupeDocs, positionCentres, nbIter, nbDistances, intraVar = k_med.k_medoides_wmd(docs, ev, distancesDocs = distances, graine = 1, nbCycles = 2)\n",
    "groupeDocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbIter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : Sans donner une taille minimale on obtient quelque chose de type 97 0 3 0 0. Prend moins de temps à calculer par contre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération du vocabulaire et de la fréquence des mots dans chaque groupe de documents :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerosGroupes = np.unique(groupeDocs)\n",
    "vocabGroupes = []\n",
    "for k in numerosGroupes:\n",
    "    vocabGroupes.append({})\n",
    "    for doc in [docs[i] for i in np.arange(len(docs))[groupeDocs == k]]:\n",
    "        mots, comptage = np.unique(doc, return_counts=True)\n",
    "        for i, mot in enumerate(mots):\n",
    "            if mot in vocabGroupes[-1]:\n",
    "                vocabGroupes[-1][mot] += comptage[i]\n",
    "            else:\n",
    "                vocabGroupes[-1][mot] = comptage[i]\n",
    "\n",
    "    vocabGroupes[-1] = {key: value for key, value in sorted(vocabGroupes[-1].items(), reverse = True, key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage du mot le plus utilisé dans chaque groupe :\n",
    "\n",
    "Ligne i : mot le plus utilisé dans le groupe i suivi du nombre de fois où on le retrouve dans le groupe 0, 1, ... etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transport : 442, 1, 18, 0, 11, \n",
      "\n",
      "plastique : 0, 357, 0, 305, 1, \n",
      "\n",
      "ville : 47, 2, 369, 1, 0, \n",
      "\n",
      "plastique : 0, 357, 0, 305, 1, \n",
      "\n",
      "produit : 10, 66, 9, 43, 689, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for d in vocabGroupes:\n",
    "    motPlusUtilise = list(d.keys())[0]\n",
    "    print(motPlusUtilise, end = ' : ')\n",
    "    for dPrim in vocabGroupes:\n",
    "        print(dPrim[motPlusUtilise] if motPlusUtilise in dPrim else '0', end = ', ')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ligne i : Mot le plus utilisé dans le groupe i et ayant le plus d'importance par rapport aux autres groupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transport [442, 1, 18, 0, 11]\n",
      "plastique [0, 357, 0, 305, 1]\n",
      "ville [47, 2, 369, 1, 0]\n",
      "bouteille [0, 29, 0, 222, 0]\n",
      "produit [10, 66, 9, 43, 689]\n"
     ]
    }
   ],
   "source": [
    "motsDisc: list[str] = [''] * len(vocabGroupes)\n",
    "quantiteMotsDisct: dict[list[int]] = {}\n",
    "for k, d in enumerate(vocabGroupes):\n",
    "    motPlusUtilise: str = None \n",
    "    freqMotPlusUtilise: float = 0\n",
    "    quantiteMotsDisct[k] = [0] * len(vocabGroupes)\n",
    "    \n",
    "\n",
    "    for mot in d:\n",
    "        temp: list[int] = []\n",
    "        for dPrim in vocabGroupes:\n",
    "            temp.append(dPrim[mot] if mot in dPrim else 0)\n",
    "        if d[mot] == max(temp) and (f := d[mot] / np.sum(temp) > freqMotPlusUtilise):\n",
    "            freqMotPlusUtilise = f\n",
    "            motPlusUtilise = mot\n",
    "            quantiteMotsDisct[k] = temp\n",
    "    \n",
    "    motsDisc[k] = motPlusUtilise\n",
    "    print(motPlusUtilise, quantiteMotsDisct[k])\n",
    "\n",
    "    \"\"\"\n",
    "    variationMotPlusUtilise: float = 0\n",
    "    for mot in d:\n",
    "        temp: list[int] = []\n",
    "        for dPrim in vocabGroupes:\n",
    "            temp.append(dPrim[mot] if mot in dPrim else 0)\n",
    "        temp = np.array(temp, dtype = np.float64)\n",
    "        if np.max(temp) == temp[k]:\n",
    "            n = np.sum(temp)\n",
    "            temp /= n\n",
    "            norme = np.linalg.norm(temp - np.max(temp), 2) ** 2\n",
    "            if norme > variationMotPlusUtilise:\n",
    "                variationMotPlusUtilise = norme\n",
    "                motPlusUtilise = mot\n",
    "    \n",
    "    motsDisc[k] = motPlusUtilise\n",
    "    print(k, temp, motPlusUtilise)\n",
    "    \"\"\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b30fa72fb85a99ca85a46e451030dfd87e2e54de7bf1c3c1af71cbda6f4de60"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
