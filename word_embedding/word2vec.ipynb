{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from gensim import models\n",
    "import numpy as np\n",
    "from typing import Callable\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import itertools\n",
    "from comparaison_BATS import *\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from clustering import k_medoides as k_med\n",
    "import distance_wmd as wmd\n",
    "import moyenne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de documents : 9501\n"
     ]
    }
   ],
   "source": [
    "with open('../data/docs.json', encoding = \"utf8\") as f:\n",
    "    docs: list[str] = json.load(f)\n",
    "print(f\"Nombre de documents : {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du vocabulaire : 7231\n"
     ]
    }
   ],
   "source": [
    "with open('../data/liste_lemmes.txt') as f:\n",
    "    vocabulaire = f.readlines()\n",
    "\n",
    "# Suppression des retours chariots sur chaque ligne\n",
    "for i in range(len(vocabulaire)):\n",
    "    vocabulaire[i] = vocabulaire[i].replace('\\n', '')\n",
    "\n",
    "print(f\"Taille du vocabulaire : {len(vocabulaire)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création et entraînement basique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `vector_size` : taille de l'espace vectoriel de représentation des mots\n",
    "- `windows` : fenêtre gauche / droite de contexte\n",
    "- `min_count` : valeur fréquence absolue minimale que doit avoir un mot pour être inclus\n",
    "- `workers` : nombre de threads utilisés pour l'entraînement\n",
    "- `sg` : 1 si Skip-Gram, 0 si CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vec: models.Word2Vec = models.Word2Vec(sentences = docs, vector_size = 300, window = 2, min_count = 1, workers = 6, sg = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# espace vectoriel généré des mots\n",
    "ev = w2vec.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enregistrement du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vec.save(\"../data/w2vec.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Récupération du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vec: models.Word2Vec = models.Word2Vec.load(\"../data/w2vec.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# espace vectoriel généré des mots\n",
    "ev = w2vec.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation qualitative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proximité de divers termes entre eux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mots_plus_proches(espace: models.KeyedVectors, mot: str, nbMots: int = 10, distance: str | Callable = 'cosine') -> list[str]:\n",
    "    resultats = {}\n",
    "    for v in vocabulaire:\n",
    "        if v != mot:\n",
    "            if distance == 'cosine':\n",
    "                resultats[v] = np.dot(espace[v], espace[mot]) / (np.linalg.norm(espace[v]) * np.linalg.norm(espace[mot]))\n",
    "\n",
    "    resultats = sorted(resultats.items(), key = lambda x: x[1], reverse = True)\n",
    "    for i in range(nbMots):\n",
    "        print(resultats[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('faire', 0.9997729)\n",
      "('nature', 0.9997668)\n",
      "('citoyen', 0.99976385)\n",
      "('être', 0.9997621)\n",
      "('france', 0.9997531)\n",
      "('environnement', 0.9997397)\n",
      "('biodiversite', 0.9997345)\n",
      "('pouvoir', 0.9997297)\n",
      "('pays', 0.99972695)\n",
      "('inciter', 0.9997259)\n"
     ]
    }
   ],
   "source": [
    "mots_plus_proches(ev, 'dechet', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analogies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mot_plus_proche(espace: models.KeyedVectors, vecteurMot: np.ndarray, nbMots: int = 5, distance: str | Callable = 'cosine') -> list[str]:\n",
    "    resultats = {}\n",
    "    for v in vocabulaire:\n",
    "        if distance == 'cosine':\n",
    "            resultats[v] = np.dot(espace[v], vecteurMot) / (np.linalg.norm(espace[v]) * np.linalg.norm(vecteurMot))\n",
    "\n",
    "    resultats = sorted(resultats.items(), key = lambda x: x[1], reverse = True)\n",
    "    for i in range(nbMots):\n",
    "        print(resultats[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('dechet', 0.96101624)\n",
      "('selectif', 0.9606815)\n",
      "('chauffer', 0.96038085)\n",
      "('centre', 0.9601055)\n",
      "('eduquer', 0.9599925)\n"
     ]
    }
   ],
   "source": [
    "variation = ev['pluie'] - ev['eau']\n",
    "mot_plus_proche(ev, ev['dechet'] + variation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation quantitative (comparaison avec un modèle stable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "traducteur = GoogleTranslator(source='en',target='fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "récupération d'un modèle word2vec de référence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://fauconnier.github.io/#data\n",
    "\n",
    "frWiki2Vec\n",
    "\n",
    "bin (151Mb)\t∨\t-\t-\tskip\t1000\t100\t5ac9\n",
    "\n",
    "https://s3.us-east-2.amazonaws.com/embeddings.net/embeddings/frWiki_no_phrase_no_postag_1000_skip_cut100.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vecR: models.KeyedVectors = models.KeyedVectors.load_word2vec_format(\"../data/frWiki_no_phrase_no_postag_1000_skip_cut100.bin\", binary=True, unicode_errors=\"ignore\")\n",
    "vocabulaireCommun = set(vocabulaire).intersection(w2vecR.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_position_proximite(modele: models.KeyedVectors, motCentral: str, mot2: str, listeMots: list[str] = None, distance: str = 'cosine') -> int:\n",
    "\n",
    "    if listeMots is None:\n",
    "        listeMots = modele.index_to_key\n",
    "\n",
    "    listeMots = listeMots.copy()\n",
    "    listeMots.remove(motCentral)\n",
    "    distMots: list[float] = []\n",
    "    pos = 1\n",
    "\n",
    "    if distance == 'cosine':\n",
    "        distMots = modele.distances(motCentral, listeMots)\n",
    "        temp = sorted(distMots)\n",
    "        pos = [temp.index(distMots[i]) for i in range(len(distMots)) if listeMots[i] == mot2][0] + 1\n",
    "        #pos = modele.rank(motCentral, mot2)\n",
    "    \n",
    "    return pos, pos / len(listeMots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3304, 0.857736240913811)\n",
      "(2284, 0.592938733125649)\n"
     ]
    }
   ],
   "source": [
    "print(get_position_proximite(w2vecR, \"vie\", \"chocolat\", list(vocabulaireCommun)))\n",
    "print(get_position_proximite(w2vec.wv,  \"vie\", \"chocolat\", list(vocabulaireCommun)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation des proximités sous BATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'taille_vocab': 3853,\n",
       " 'nb_comp': 179,\n",
       " 'rmse_freq': 0.38301971232118665,\n",
       " 'err_moy_freq': 0.23272048451671376,\n",
       " 'err_dis_cos': -0.6540805354466759,\n",
       " 'rmse_dis_cos': 0.6860216614593655}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stats_comparaisons_BATS(ev, w2vecR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moyenne des similarités entre chaque mot du vocabulaire des deux modèles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_comparaisons_intra_vocab(modele: models.KeyedVectors, reference: models.KeyedVectors):\n",
    "\n",
    "    vocabulaire = list(set(modele.index_to_key).intersection(reference.index_to_key))\n",
    "    stats = {}\n",
    "    stats['taille_vocab'] = len(vocabulaire)\n",
    "    stats['err_dis_cos'] = 0\n",
    "    n = 0\n",
    "    for mot1, mot2 in itertools.product(vocabulaire, vocabulaire):\n",
    "        n += 1\n",
    "        if mot1 == mot2:\n",
    "            continue\n",
    "        \n",
    "        # Distance cosinus\n",
    "        disMod = modele.distance(mot1, mot2)\n",
    "        disRef = modele.distance(mot1, mot2)\n",
    "        stats['err_dis_cos'] += disMod - disRef\n",
    "    \n",
    "    stats['err_dis_cos'] /= n\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_comparaisons_intra_vocab(ev, w2vecR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparamètres considérés : \n",
    "- Type de modèle (CBOW, Skip-Gram) ;\n",
    "- Taille de l'espace vectoriel (100 à 300) ;\n",
    "- Taille de la fenêtre de contexte (2 à 6) ;\n",
    "- Fréquence minimale des mots que l'on doit considérer (1, 2) ;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning(documents : list[str], modeleReference: models.KeyedVectors):\n",
    "\n",
    "    # Grille des hyperparamètres\n",
    "    typesModele = [0, 1]\n",
    "    taillesEV = range(100, 301, 50)\n",
    "    taillesFenetre = range(2, 7)\n",
    "    frequencesMin = [1, 2]\n",
    "\n",
    "    nbModeles: int = len(typesModele * len(taillesEV) * len(taillesFenetre) * len(frequencesMin))\n",
    "    print(f\"Nombre de modèles à tester : {nbModeles}\")\n",
    "    print(\"0 % | \", end = '')\n",
    "    tableauModeles = pd.DataFrame(columns = [\"type_modele\", \"dimension_ev\", \"taille_fenetre\", \"frequence_min\",\n",
    "    \"err_dis_cos\", 'rmse_dis_cos', 'err_moy_freq', 'rmse_freq'])\n",
    "\n",
    "    modelesFaits = 0\n",
    "    score = np.inf\n",
    "    bestModele: models.Word2Vec = None\n",
    "    meilleursHP = {}\n",
    "    # Réalisation d'un modèle pour chaque point de la grille\n",
    "    for typeModele, N, fenetre, frequenceMin in itertools.product(typesModele, taillesEV, taillesFenetre, frequencesMin):\n",
    "\n",
    "        modele = models.Word2Vec(sentences = documents,  vector_size = N, window = fenetre, min_count = frequenceMin, workers = 6, sg = typeModele)\n",
    "        stats = get_stats_comparaisons_BATS(modele.wv, modeleReference)\n",
    "\n",
    "        tableauModeles.loc[len(tableauModeles.index)] = [\"Skip-Gram\" if typeModele else \"CBOW\", N,\n",
    "        fenetre, frequenceMin, stats[\"err_dis_cos\"], stats[\"rmse_dis_cos\"], stats['err_moy_freq'], stats['rmse_freq']]\n",
    "        \n",
    "        modelesFaits += 1\n",
    "        if (percent := round(modelesFaits * 100 / nbModeles)) % 5 == 0 and round((modelesFaits -1) * 100 / nbModeles) != 0:\n",
    "            print(f\"{percent} % |\", end = \" \")\n",
    "\n",
    "    return tableauModeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    tableauModeles = tuning(docs, w2vecR)\n",
    "    tableauModeles\n",
    "    minRMSEDisCos = np.min(tableauModeles['rmse_dis_cos'])\n",
    "    tableauModeles.loc[tableauModeles['rmse_dis_cos'] == minRMSEDisCos, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Espace de documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Valeur moyenne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction suivante transforme un document en vecteurs en faisant la moyenne de la représentation vectorielle de ses mots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wvs_to_doc(doc: list[str], w2v: Callable, method: str = 'mean') -> np.ndarray:\n",
    "\n",
    "    if method == 'mean':\n",
    "\n",
    "        mean = np.zeros(len(w2v(doc[0])))\n",
    "        for mot in doc:\n",
    "            mean += w2v(mot)\n",
    "        mean /= len(doc)\n",
    "\n",
    "        return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "toVec = lambda mot: ev[mot]\n",
    "\n",
    "meanDocs = []\n",
    "for doc in docs:\n",
    "    meanDocs.append(wvs_to_doc(doc, toVec))\n",
    "meanDocs = np.array(meanDocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = moyenne.word_emb_vers_doc_emb_moyenne(docs, ev, methode = 'TF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.51594402e-02,  1.35727882e-01, -1.71253774e-02,  7.07388893e-02,\n",
       "       -8.44135042e-03, -1.37660921e-01,  8.86219889e-02,  2.52207905e-01,\n",
       "        4.67072204e-02, -1.49624124e-02, -2.99011497e-03, -1.55802593e-01,\n",
       "        2.78197210e-02, -4.27544340e-02, -1.25372216e-01, -9.51578617e-02,\n",
       "        3.66431177e-02,  1.82122476e-02,  5.63850179e-02, -6.56555174e-03,\n",
       "       -1.20594077e-01,  3.25088482e-03,  8.05400833e-02,  6.81664888e-03,\n",
       "        1.21224396e-01,  1.46642132e-02, -1.51066571e-01, -1.66745801e-02,\n",
       "       -8.23311880e-02, -9.88011658e-02,  4.41608690e-02, -1.06073201e-01,\n",
       "        4.18942310e-02, -2.43917592e-02, -2.47597508e-02,  2.25639232e-02,\n",
       "        4.28290330e-02, -1.29628867e-01, -2.09489092e-02,  8.81281309e-03,\n",
       "       -6.97190464e-02, -8.43129028e-03,  1.82562079e-02, -9.07807574e-02,\n",
       "        4.81138900e-02,  1.23819314e-01,  5.46163656e-02,  3.78300697e-02,\n",
       "       -5.21696620e-02,  1.10731520e-01,  3.37265804e-02, -6.49669347e-03,\n",
       "       -6.01511002e-02,  3.23747881e-02, -1.75446328e-02,  1.48021668e-01,\n",
       "        5.94392903e-02,  4.35170438e-03,  2.47400049e-02, -1.10115688e-02,\n",
       "       -6.36349171e-02, -3.75995673e-02, -2.91028060e-02,  3.22399586e-02,\n",
       "        5.05449884e-02,  4.07518446e-02,  2.49457005e-02, -1.29551925e-02,\n",
       "       -4.37062196e-02, -6.20495863e-02, -5.27885789e-03,  9.81228128e-02,\n",
       "        1.34455666e-01, -1.14933692e-01, -4.71158000e-03,  5.75411431e-02,\n",
       "       -1.14218272e-01, -5.96850831e-03, -4.68963757e-04,  9.98476595e-02,\n",
       "       -4.38520163e-02, -1.22377239e-01,  3.31623331e-02,  1.96950674e-01,\n",
       "        3.68328989e-02,  2.14147614e-04, -9.68095958e-02,  7.63829751e-03,\n",
       "        7.50712454e-02,  4.62487228e-02,  1.25446960e-01, -5.89177087e-02,\n",
       "        7.15345815e-02,  6.19522370e-02,  9.46014076e-02,  9.56745669e-02,\n",
       "        1.22451358e-01, -3.72542664e-02, -8.13710615e-02,  1.00617498e-01,\n",
       "       -5.35486080e-03, -5.45044355e-02,  1.19132385e-01, -1.19931307e-02,\n",
       "        4.65498343e-02, -8.16367865e-02, -3.17361467e-02,  2.49763671e-02,\n",
       "       -6.45568967e-02,  8.23301822e-02, -1.00412562e-01, -5.55133298e-02,\n",
       "       -7.54411472e-03,  8.28389227e-02,  7.60697275e-02,  6.51486814e-02,\n",
       "       -2.07569748e-02, -3.15433145e-02,  1.71900526e-01, -1.03367761e-01,\n",
       "        8.01649839e-02,  1.02756128e-01,  5.96376546e-02, -9.44154616e-03,\n",
       "       -3.62044387e-02,  4.53323610e-02,  8.17140713e-02, -1.21461466e-01,\n",
       "       -1.74211282e-02,  3.99699919e-02,  2.37680189e-02,  1.22030407e-01,\n",
       "        1.19903916e-02, -9.39722806e-02,  6.78304583e-02,  5.26556224e-02,\n",
       "       -4.08201069e-02, -9.77617502e-02, -8.61654058e-02, -1.31272838e-01,\n",
       "        3.67289484e-02, -1.43056005e-01,  5.81699330e-03,  6.27990812e-02,\n",
       "        7.51432851e-02, -4.60146330e-02, -1.85229227e-01, -2.98385397e-02,\n",
       "        4.80080359e-02, -4.42546792e-02,  2.66617499e-02, -1.87147200e-01,\n",
       "       -9.40906778e-02, -5.55221513e-02,  5.13805076e-03,  4.84519191e-02,\n",
       "       -1.01747572e-01, -5.54490164e-02, -2.11677440e-02,  1.23759851e-01,\n",
       "        3.41342837e-02,  6.96493238e-02, -1.75602913e-01,  1.35999396e-01,\n",
       "       -7.54391849e-02,  5.01576848e-02,  1.78401023e-02, -3.66936508e-03,\n",
       "        5.83346710e-02,  2.03922570e-01, -2.97049992e-02, -1.26551380e-02,\n",
       "        5.10844663e-02,  3.15546617e-02, -4.87686060e-02,  1.70679875e-02,\n",
       "       -1.73375756e-02, -1.04553752e-01, -5.66749461e-02, -1.62777305e-02,\n",
       "       -5.63118160e-02,  7.79510736e-02, -5.75103164e-02, -7.20397457e-02,\n",
       "       -7.50489347e-03,  6.45663366e-02,  1.03087477e-01,  1.44133896e-01,\n",
       "        5.11891395e-02, -1.11866936e-01, -1.28329704e-02, -2.66671386e-02,\n",
       "       -1.36040911e-01,  6.12746459e-03,  5.59362732e-02, -8.68944526e-02,\n",
       "        1.38659896e-02, -1.22967437e-01,  5.95984422e-02, -1.70961525e-02,\n",
       "       -1.22929066e-01,  3.32471579e-02, -1.75402183e-02, -5.51419817e-02,\n",
       "       -4.24666256e-02, -9.88683384e-03, -5.47980256e-02,  3.77010666e-02,\n",
       "        1.09274555e-02, -2.42985301e-02,  2.82661133e-02, -7.24076778e-02,\n",
       "       -1.02524295e-01, -3.61265577e-02,  6.98295683e-02, -1.26411080e-01,\n",
       "        1.01805117e-03, -2.01565191e-01, -1.57879025e-01, -9.82464626e-02,\n",
       "        1.26434177e-01, -1.16315659e-03, -8.59994143e-02, -6.37723058e-02,\n",
       "       -5.78046739e-02, -8.47247764e-02,  1.95533875e-02, -2.72993464e-04,\n",
       "       -8.83777514e-02,  5.31333089e-02,  1.02886260e-01, -2.00494099e-03,\n",
       "       -8.14056247e-02,  8.40265676e-02, -3.21410708e-02,  1.53859956e-02,\n",
       "       -2.93613004e-04,  1.28032910e-02,  4.04406376e-02, -1.60784051e-01,\n",
       "        1.57954767e-02, -5.93262613e-02, -9.35378447e-02,  1.01622688e-02,\n",
       "       -1.68015081e-02, -1.28168836e-01,  3.44751850e-02,  3.34663652e-02,\n",
       "        9.44027212e-03,  1.09661728e-01, -7.07058934e-03,  7.41897076e-02,\n",
       "        3.13616730e-02, -2.37388397e-03, -1.61276877e-01, -9.47185904e-02,\n",
       "        1.62488654e-01,  3.97846438e-02, -1.75874129e-01, -5.70292249e-02,\n",
       "        8.07646438e-02,  1.10161513e-01, -2.32290961e-02, -1.55020908e-01,\n",
       "       -8.36690441e-02, -1.13380160e-02,  5.34567796e-02,  6.04957603e-02,\n",
       "       -9.08011347e-02,  2.50866413e-02, -7.66452253e-02,  1.20499674e-02,\n",
       "       -1.53861446e-02, -4.59028035e-02,  1.55506611e-01,  5.69602055e-03,\n",
       "        1.30728215e-01,  1.88094527e-02, -8.64545703e-02, -1.15381205e-03,\n",
       "        9.79546458e-02, -2.09238529e-02, -1.65102556e-02,  7.60788023e-02,\n",
       "        3.74033675e-02, -4.17010710e-02, -1.46991283e-01,  5.17809317e-02,\n",
       "        2.81874314e-02,  1.41106144e-01, -2.43406650e-02,  1.43541336e-01,\n",
       "        1.41068235e-01,  4.77575185e-03,  1.21708058e-01,  1.68552637e-01,\n",
       "        1.97760481e-02, -8.93963426e-02,  6.80091903e-02, -1.91119146e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('faire', 0.9999092)\n",
      "('environnemental', 0.9998653)\n",
      "('être', 0.999865)\n",
      "('environnement', 0.9998618)\n",
      "('citoyen', 0.9998591)\n"
     ]
    }
   ],
   "source": [
    "mot_plus_proche(ev, res[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['unioneuropeenne',\n",
       " 'impose',\n",
       " 'regle',\n",
       " 'environnemental',\n",
       " 'partenaire',\n",
       " 'continuer',\n",
       " 'faire',\n",
       " 'affaire']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Distance WMD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de distances à calculer : 4950.0\n",
      "0 % | 5 % | 10 % | 15 % | 20 % | 25 % | 30 % | 35 % | 40 % | 45 % | 50 % | 55 % | 60 % | 65 % | 70 % | 75 % | 80 % | 85 % | 90 % | 95 % | 100 % | Données enregistrées dans ../data/distances/distances.7z\n"
     ]
    }
   ],
   "source": [
    "wmd.distance_wmd_tous_docs(docs[:100], modele = ev, retour = 'fichier', toInteger = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     uint32\n",
       "1     uint32\n",
       "2     uint32\n",
       "3     uint32\n",
       "4     uint32\n",
       "       ...  \n",
       "95    uint32\n",
       "96    uint32\n",
       "97    uint32\n",
       "98    uint32\n",
       "99    uint32\n",
       "Length: 100, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wmd.lecture_fichier_distances_wmd().dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prend dans notre cas 3h45min environ de calcul\n",
    "if False:\n",
    "    wmddistance_wmd_tous_docs(docs, ev, retour = 'fichier', nomFichier = 'wmd/w2vec.txt', toInteger = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = wmd.lecture_fichier_distances_wmd('../data/wmd/w2vec.txt', integer = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cycle 1 :\n",
      "Itération 1 : Création des groupes - Correction des tailles de groupe - part dans chaque groupe (%) : 5 5 80 5 5 (784 s) | Recherche du point moyen pour chaque groupe ( 0 1 2 3 4 ) - Stabilité des centres : X X X X X (194 s)\n",
      "Itération 2 : Création des groupes - Correction des tailles de groupe - part dans chaque groupe (%) : 6 10 39 5 39 (75 s) | Recherche du point moyen pour chaque groupe ( 0 1 2 3 4 ) - Stabilité des centres : V V X V V (97 s)\n",
      "Itération 3 : Création des groupes - Correction des tailles de groupe - part dans chaque groupe (%) : 6 9 61 5 19 (74 s) | Recherche du point moyen pour chaque groupe ( 0 1 2 3 4 ) - Stabilité des centres : V V V V V (128 s)\n",
      "Cycle 2 :\n",
      "Itération 1 : Création des groupes - Correction des tailles de groupe - part dans chaque groupe (%) : 80 5 5 5 5 (924 s) | Recherche du point moyen pour chaque groupe ( 0 1 2 3 4 ) - Stabilité des centres : X X X X X (205 s)\n",
      "Itération 2 : Création des groupes - Correction des tailles de groupe - part dans chaque groupe (%) : 5 41 24 23 7 (102 s) | Recherche du point moyen pour chaque groupe ( 0 1 2 3 4 ) - Stabilité des centres : X X X X X (93 s)\n",
      "Itération 3 : Création des groupes - Correction des tailles de groupe - part dans chaque groupe (%) : 59 5 11 16 8 (124 s) | Recherche du point moyen pour chaque groupe ( 0 1 2 3 4 ) - Stabilité des centres : X X X V X (129 s)\n",
      "Itération 4 : Création des groupes - part dans chaque groupe (%) : 10 58 10 14 7 (3 s) | Recherche du point moyen pour chaque groupe ( 0 1 2 3 4 ) - Stabilité des centres : V V X V V (122 s)\n",
      "Itération 5 : Création des groupes - part dans chaque groupe (%) : 10 59 8 15 8 (3 s) | Recherche du point moyen pour chaque groupe ( 0 1 2 3 4 ) - Stabilité des centres : V V X V V (125 s)\n",
      "Itération 6 : Création des groupes - part dans chaque groupe (%) : 10 59 7 15 9 (3 s) | Recherche du point moyen pour chaque groupe ( 0 1 2 3 4 ) - Stabilité des centres : V V V V V (127 s)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       4\n",
       "4       4\n",
       "       ..\n",
       "9496    2\n",
       "9497    2\n",
       "9498    1\n",
       "9499    2\n",
       "9500    2\n",
       "Name: 2, Length: 9501, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupeDocs, positionCentres, nbIter, nbDistances, intraVar = k_med.k_medoides_wmd(docs, ev, distancesDocs = distances, graine = 1, nbCycles = 2)\n",
    "groupeDocs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nbIter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note : Sans donner une taille minimale on obtient quelque chose de type 97 0 3 0 0. Prend moins de temps à calculer par contre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération du vocabulaire et de la fréquence des mots dans chaque groupe de documents :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerosGroupes = np.unique(groupeDocs)\n",
    "vocabGroupes = []\n",
    "for k in numerosGroupes:\n",
    "    vocabGroupes.append({})\n",
    "    for doc in [docs[i] for i in np.arange(len(docs))[groupeDocs == k]]:\n",
    "        mots, comptage = np.unique(doc, return_counts=True)\n",
    "        for i, mot in enumerate(mots):\n",
    "            if mot in vocabGroupes[-1]:\n",
    "                vocabGroupes[-1][mot] += comptage[i]\n",
    "            else:\n",
    "                vocabGroupes[-1][mot] = comptage[i]\n",
    "\n",
    "    vocabGroupes[-1] = {key: value for key, value in sorted(vocabGroupes[-1].items(), reverse = True, key=lambda item: item[1])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affichage du mot le plus utilisé dans chaque groupe :\n",
    "\n",
    "Ligne i : mot le plus utilisé dans le groupe i suivi du nombre de fois où on le retrouve dans le groupe 0, 1, ... etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transport : 442, 1, 18, 0, 11, \n",
      "\n",
      "plastique : 0, 357, 0, 305, 1, \n",
      "\n",
      "ville : 47, 2, 369, 1, 0, \n",
      "\n",
      "plastique : 0, 357, 0, 305, 1, \n",
      "\n",
      "produit : 10, 66, 9, 43, 689, \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for d in vocabGroupes:\n",
    "    motPlusUtilise = list(d.keys())[0]\n",
    "    print(motPlusUtilise, end = ' : ')\n",
    "    for dPrim in vocabGroupes:\n",
    "        print(dPrim[motPlusUtilise] if motPlusUtilise in dPrim else '0', end = ', ')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ligne i : Mot le plus utilisé dans le groupe i et ayant le plus d'importance par rapport aux autres groupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transport [442, 1, 18, 0, 11]\n",
      "plastique [0, 357, 0, 305, 1]\n",
      "ville [47, 2, 369, 1, 0]\n",
      "bouteille [0, 29, 0, 222, 0]\n",
      "produit [10, 66, 9, 43, 689]\n"
     ]
    }
   ],
   "source": [
    "motsDisc: list[str] = [''] * len(vocabGroupes)\n",
    "quantiteMotsDisct: dict[list[int]] = {}\n",
    "for k, d in enumerate(vocabGroupes):\n",
    "    motPlusUtilise: str = None \n",
    "    freqMotPlusUtilise: float = 0\n",
    "    quantiteMotsDisct[k] = [0] * len(vocabGroupes)\n",
    "    \n",
    "\n",
    "    for mot in d:\n",
    "        temp: list[int] = []\n",
    "        for dPrim in vocabGroupes:\n",
    "            temp.append(dPrim[mot] if mot in dPrim else 0)\n",
    "        if d[mot] == max(temp) and (f := d[mot] / np.sum(temp) > freqMotPlusUtilise):\n",
    "            freqMotPlusUtilise = f\n",
    "            motPlusUtilise = mot\n",
    "            quantiteMotsDisct[k] = temp\n",
    "    \n",
    "    motsDisc[k] = motPlusUtilise\n",
    "    print(motPlusUtilise, quantiteMotsDisct[k])\n",
    "\n",
    "    \"\"\"\n",
    "    variationMotPlusUtilise: float = 0\n",
    "    for mot in d:\n",
    "        temp: list[int] = []\n",
    "        for dPrim in vocabGroupes:\n",
    "            temp.append(dPrim[mot] if mot in dPrim else 0)\n",
    "        temp = np.array(temp, dtype = np.float64)\n",
    "        if np.max(temp) == temp[k]:\n",
    "            n = np.sum(temp)\n",
    "            temp /= n\n",
    "            norme = np.linalg.norm(temp - np.max(temp), 2) ** 2\n",
    "            if norme > variationMotPlusUtilise:\n",
    "                variationMotPlusUtilise = norme\n",
    "                motPlusUtilise = mot\n",
    "    \n",
    "    motsDisc[k] = motPlusUtilise\n",
    "    print(k, temp, motPlusUtilise)\n",
    "    \"\"\""
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b30fa72fb85a99ca85a46e451030dfd87e2e54de7bf1c3c1af71cbda6f4de60"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
